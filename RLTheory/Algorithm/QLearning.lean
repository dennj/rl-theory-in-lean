import Mathlib.Probability.ProbabilityMassFunction.Basic
import Mathlib.LinearAlgebra.FiniteDimensional.Basic

import RLTheory.Defs
import RLTheory.MeasureTheory.MeasurableSpace.Constructions
import RLTheory.MeasureTheory.Group.Arithmetic
import RLTheory.StochasticApproximation.IIDSamples
import RLTheory.StochasticApproximation.MarkovSamples
import RLTheory.Probability.MarkovChain.Defs
import RLTheory.Probability.MarkovChain.Finite.Defs
import RLTheory.Probability.MarkovChain.Trajectory
import RLTheory.MarkovDecisionProcess.MarkovDecisionProcess

open ENNReal NNReal Real Finset Filter TopologicalSpace Filter MeasureTheory.Filtration MeasureTheory ProbabilityTheory StochasticApproximation StochasticMatrix Preorder RLTheory Matrix MarkovChain
open scoped MeasureTheory ProbabilityTheory Topology InnerProductSpace RealInnerProductSpace Gradient

lemma abs_sup'_sub_sup'_le_sup'
  {Œπ} {s : Finset Œπ} (hs : s.Nonempty) {x y : Œπ ‚Üí ‚Ñù} :
  |s.sup' hs x - s.sup' hs y| ‚â§ s.sup' hs (fun i => |x i - y i|) := by
  apply abs_le.mpr
  constructor
  case left =>
    simp
    intro i hi
    have : y i = x i + (y i - x i) := by ring_nf
    rw [this]
    apply add_le_add
    simp
    use i
    grw [le_abs_self (y i - x i)]
    rw [‚Üêneg_sub, abs_neg]
    simp
    use i
  case right =>
    simp
    obtain ‚ü®i, his, hi‚ü© := exists_mem_eq_sup' hs fun i => |x i - y i|
    use i
    constructor
    exact his
    intro j hj
    have : x j = x j - y j + y j := by ring_nf
    rw [this]
    apply add_le_add
    grw [le_abs_self (x j - y j)]
    rw [‚Üêhi]
    apply (le_sup'_iff hs).mpr
    use j
    simp
    use j

lemma sum_probability_singleton {Œπ} [Fintype Œπ] [MeasurableSpace Œπ]
  [MeasurableSingletonClass Œπ]
  (Œº : ProbabilityMeasure Œπ) :
  ‚àë i, Œº {i} = 1 := by
  have : ‚àë i, Œº.1 {i} = 1 := by simp
  have := congrArg ENNReal.toNNReal this
  conv_rhs at this => simp
  rw [ENNReal.toNNReal_sum] at this
  rw [‚Üêthis]
  apply sum_congr rfl
  intro i hi
  exact_mod_cast rfl
  simp

namespace ReinforcementLearning.QLearning

universe u
variable {S : Type u} [Fintype S] [DecidableEq S] [Nonempty S]
variable [MeasurableSpace S] [MeasurableSingletonClass S]
variable {A: Type u} [Fintype A] [DecidableEq A] [Nonempty A]
variable [MeasurableSpace A] [MeasurableSingletonClass A]

noncomputable def sa_to_fin (y : S √ó A) : Fin (Fintype.card (S √ó A)) :=
  Fintype.equivFin (S √ó A) y

noncomputable def fin_to_sa (y : Fin (Fintype.card (S √ó A))) : S √ó A :=
  (Fintype.equivFin (S √ó A)).symm y

variable {d : ‚Ñï}
abbrev LinftySpace (d : ‚Ñï) := PiLp ‚ä§ (fun _ : Fin d => ‚Ñù)
def toLinfty (x : E d) : LinftySpace d := x
def toL2 (x : LinftySpace d) : E d := x
def ftoLinfty (f : E d ‚Üí E d) : LinftySpace d ‚Üí LinftySpace d :=
  toLinfty ‚àò f ‚àò toL2

local notation (priority := 2000) "‚Äñ" x "‚Äñ‚àû" =>
  @Norm.norm (PiLp ‚ä§ fun _ => ‚Ñù) _ x

structure QLearningSpec extends FiniteMDP (S := S) (A := A) where
  Œ± : ‚Ñï ‚Üí ‚Ñù
  q‚ÇÄ : E (Fintype.card (S √ó A))

variable {spec : QLearningSpec (S := S) (A := A)}

noncomputable def QLearningSpec.max‚Çê
  (q : E (Fintype.card (S √ó A))) (s : S) : ‚Ñù :=
  Finset.univ.sup' (by simp) (fun a => q (sa_to_fin (s, a)))

noncomputable def QLearningSpec.bellman_op
  (q : E (Fintype.card (S √ó A))) : E (Fintype.card (S √ó A)) :=
  fun i =>
    let sa := fin_to_sa i
    spec.r sa + spec.Œ≥ * ‚àë s', spec.P sa {s'} * max‚Çê q s'

lemma QLearningSpec.contraction_of_bellman_op :
  ContractingWith ‚ü®spec.Œ≥, by exact spec.hŒ≥.1‚ü© (ftoLinfty spec.bellman_op)
  := by
  constructor
  exact_mod_cast spec.hŒ≥.2
  apply lipschitzWith_iff_norm_sub_le.mpr
  intro q q'
  unfold ftoLinfty
  simp [toL2, toLinfty]
  unfold bellman_op
  simp
  rw [Pi.sub_def]
  simp
  simp_rw [‚Üêmul_sub, ‚Üêsum_sub_distrib, ‚Üêmul_sub]
  conv_lhs => simp [Norm.norm]
  apply (ciSup_le_iff ?_).mpr
  intro i
  rw [abs_mul]
  grw [abs_sum_le_sum_abs]
  simp_rw [abs_mul]
  rw [abs_of_nonneg spec.hŒ≥.1]
  apply mul_le_mul_of_nonneg_left
  have : ‚àÄ s', |max‚Çê q s' - max‚Çê q' s'| ‚â§ ‚Äñq - q'‚Äñ := by
    intro s'
    simp [max‚Çê]
    grw [abs_sup'_sub_sup'_le_sup' (by simp)]
    simp
    intro a'
    apply LE.le.trans
    rotate_left
    apply PiLp.norm_apply_le (p := ‚ä§) (q - q') (sa_to_fin (s', a'))
    simp
  grw [sum_le_sum]
  rotate_left
  intro s' hs'
  grw [this s']
  exact spec.hŒ≥.1
  apply Set.Finite.bddAbove
  apply Finite.Set.finite_range
  rw [‚Üêsum_mul]
  conv_rhs => rw [‚Üêone_mul ‚Äñq - q'‚Äñ]
  apply mul_le_mul_of_nonneg_right
  apply le_of_eq
  simp
  simp [‚Üêcoe_sum, sum_probability_singleton]
  apply norm_nonneg

noncomputable def QLearningSpec.optimal_q :=
  toL2 (ContractingWith.fixedPoint (ftoLinfty spec.bellman_op)
    spec.contraction_of_bellman_op)

noncomputable def QLearningSpec.x (y : S √ó A) : E (Fintype.card (S √ó A)) :=
  fun i => if i = sa_to_fin y then 1 else 0

noncomputable def QLearningSpec.update
  (q : E (Fintype.card (S √ó A))) (y : (S √ó A) √ó (S √ó A)) :
  E (Fintype.card (S √ó A)) :=
  (spec.r y.1 + spec.Œ≥ * max‚Çê q y.2.1 - q (sa_to_fin y.1)) ‚Ä¢ x y.1

omit [Nonempty S] in
lemma QLearningSpec.lipschitz_of_update :
  ‚àÉ C, 0 ‚â§ C ‚àß ‚àÄ z z' y,
    ‚Äñspec.update z y - spec.update z' y‚Äñ ‚â§ C * ‚Äñz - z'‚Äñ := by
    refine ‚ü®?L, ?hLnonneg, ?hL‚ü©
    case L => exact (|spec.Œ≥| + 1)
    case hLnonneg => positivity
    case hL =>
      unfold update
      intro z z' y
      rcases y with ‚ü®y, y'‚ü©
      rw [‚Üêsub_smul, norm_smul]
      rw [sub_sub_sub_comm, add_sub_add_comm]
      simp [-PiLp.inner_apply]
      rw [‚Üêmul_sub]
      grw [abs_sub_le (b := 0)]
      simp [-PiLp.inner_apply]
      rw [abs_mul]
      simp [max‚Çê]
      grw [abs_sup'_sub_sup'_le_sup' (by simp)]
      have := PiLp.norm_apply_le (p := ‚ä§) (z' - z) (sa_to_fin y)
      simp at this
      grw [this]
      conv_lhs => simp [PiLp.norm_eq_sum, x]
      grw [sup'_le (a := ‚Äñz - z'‚Äñ‚àû)]
      grw [Linfty_le_Lp, Linfty_le_Lp]
      apply le_of_eq
      rw [‚Üêneg_sub (b := z'), norm_neg (a := z - z')]
      ring_nf
      simp
      simp
      intro a' ha'
      have := PiLp.norm_apply_le (p := ‚ä§) (z - z') (sa_to_fin (y'.1, a'))
      simp at this
      exact this

omit [Nonempty S] in
lemma QLearningSpec.measurable_of_udpate : Measurable (spec.update.uncurry)
  := by
  apply Measurable.smul
  apply Measurable.add
  apply Measurable.add
  apply Measurable.comp
  apply measurable_of_countable
  apply Measurable.comp
  apply Measurable.fst
  apply measurable_id
  apply Measurable.snd
  apply measurable_id
  apply Measurable.mul
  apply measurable_const
  simp [max‚Çê]
  apply Measurable.congr
  ext wy
  rw [sup'_univ_eq_ciSup]
  apply Measurable.iSup
  intro a'
  let f : E (Fintype.card (S √ó A)) ‚Üí (S √ó A) √ó S √ó A ‚Üí ‚Ñù :=
    fun q y => q (sa_to_fin (y.2.1, a'))
  apply Measurable.congr (f := f.uncurry)
  rfl
  apply measurable_uncurry_of_continuous_of_measurable
  intro y
  simp [f]; apply continuous_pi_iff.mp; apply continuous_id
  intro q
  simp [f, sa_to_fin]
  apply Measurable.comp (by apply measurable_of_countable)
  apply Measurable.comp (by apply measurable_of_countable)
  apply Measurable.prodMk
  apply Measurable.fst
  apply Measurable.snd
  apply measurable_id
  apply measurable_const
  apply Measurable.neg
  let f : E (Fintype.card (S √ó A)) ‚Üí (S √ó A) √ó S √ó A ‚Üí ‚Ñù :=
    fun q y => q (sa_to_fin y.1)
  apply Measurable.congr (f := f.uncurry)
  rfl
  apply measurable_uncurry_of_continuous_of_measurable
  intro y
  simp [f]; apply continuous_pi_iff.mp; apply continuous_id
  intro q
  simp [f, sa_to_fin]
  apply Measurable.comp (by apply measurable_of_countable)
  apply Measurable.comp (by apply measurable_of_countable)
  apply Measurable.fst
  apply measurable_id
  unfold QLearningSpec.x
  apply measurable_pi_iff.mpr
  intro q
  let f : E (Fintype.card (S √ó A)) ‚Üí (S √ó A) √ó S √ó A ‚Üí ‚Ñù :=
    fun w y => if q = sa_to_fin y.1 then 1 else 0
  apply Measurable.congr (f := f.uncurry)
  rfl
  apply measurable_uncurry_of_continuous_of_measurable
  intro y
  simp [f]
  apply continuous_const
  intro w
  simp [f]
  apply measurable_of_countable

noncomputable def QLearningSpec.expected_update
  (q : E (Fintype.card (S √ó A))) : E (Fintype.card (S √ó A)) :=
  ‚àë y, ‚àë y', (spec.MRP.Œº y * spec.MRP.P y y') ‚Ä¢ spec.update q (y, y')

noncomputable def QLearningSpec.update_target
  (q : E (Fintype.card (S √ó A))) (y : (S √ó A) √ó (S √ó A)) :
  E (Fintype.card (S √ó A)) :=
  spec.update q y + q

omit [Nonempty S] in
lemma QLearningSpec.lipschitz_of_update_target :
  ‚àÉ C, 0 ‚â§ C ‚àß ‚àÄ z z' y,
    ‚Äñspec.update_target z y - spec.update_target z' y‚Äñ ‚â§ C * ‚Äñz - z'‚Äñ := by
  obtain ‚ü®C, hCnonneg, hC‚ü© := spec.lipschitz_of_update
  refine ‚ü®?L, ?hLnonneg, ?hL‚ü©
  case L => exact C + 1
  case hLnonneg => positivity
  case hL =>
    unfold update_target
    intro z z' y
    rw [add_sub_add_comm]
    grw [norm_add_le, hC]
    ring_nf
    rfl

omit [Nonempty S] in
lemma QLearningSpec.measurable_of_udpate_target :
  Measurable (spec.update_target.uncurry) := by
  apply Measurable.add
  apply spec.measurable_of_udpate
  measurability

noncomputable def QLearningSpec.expected_update_target :=
  spec.expected_update + id

lemma QLearningSpec.expected_update_target_eq
  (q : E (Fintype.card (S √ó A))) :
  spec.expected_update_target q =
    fun i => spec.MRP.Œº (fin_to_sa i) * (spec.bellman_op q - q) i + q i
  := by
  have hP : RowStochastic spec.MRP.P := by infer_instance
  simp [expected_update_target, expected_update, update]
  simp [‚ÜêPi.add_def]
  simp_rw [smul_smul, ‚Üêsum_smul, mul_assoc, ‚Üêmul_sum]
  let g := fun i =>
    let sa := fin_to_sa i
    (spec.MRP.Œº sa * ‚àë y, spec.MRP.P sa y *
      (spec.r sa + spec.Œ≥ * max‚Çê q y.1 - q i)) ‚Ä¢ x sa
  rw [sum_equiv (s := univ) (t := univ) (Fintype.equivFin (S √ó A)) (g := g)]
  simp [g]
  ext i
  rw [Finset.sum_apply]
  simp [x]
  have : ‚àÄ y, i = sa_to_fin (fin_to_sa y) ‚Üî i = y := by simp [sa_to_fin, fin_to_sa]
  conv_lhs =>
    congr; rfl; ext y; rw [if_congr (this y) (by rfl) (by rfl)]
  simp
  apply Or.inl
  simp_rw [mul_sub, sum_sub_distrib, ‚Üêsum_mul, mul_add, sum_add_distrib, ‚Üêsum_mul]
  simp [(hP.stochastic (fin_to_sa i)).rowsum, bellman_op]
  move_mul [spec.Œ≥]
  simp [‚Üêsum_mul]
  apply Or.inl
  simp_rw [FiniteMDP.MRP.P_apply ?_]
  simp [Fintype.sum_prod_type]
  simp_rw [mul_assoc, ‚Üêmul_sum]
  apply sum_congr rfl
  intro s' hs'
  simp
  apply Or.inl
  simp [‚Üêsum_mul, ‚Üêcoe_sum, sum_probability_singleton]
  simp
  intro y hy
  have : y = fin_to_sa (sa_to_fin y) := by simp [sa_to_fin, fin_to_sa]
  nth_rw 1 [this]
  nth_rw 2 [this]
  nth_rw 3 [this]
  nth_rw 5 [this]
  simp [sa_to_fin, g]

lemma QLearningSpec.unfold_expected_update_target
  (q : E (Fintype.card (S √ó A))) :
  spec.expected_update_target q =
    ‚àë y, ‚àë y', (spec.MRP.Œº y * spec.MRP.P y y') ‚Ä¢ spec.update_target q (y, y')
    := by
  have hP : RowStochastic spec.MRP.P := by infer_instance
  have hŒº : StochasticVec spec.MRP.Œº := by infer_instance
  simp [expected_update_target, update_target, expected_update]
  simp_rw [sum_add_distrib, ‚Üêsum_smul]
  simp
  simp_rw [‚Üêmul_sum, (hP.stochastic ?_).rowsum]
  simp [hŒº.rowsum]

lemma QLearningSpec.isFixedPoint_optimal_q :
  spec.expected_update_target spec.optimal_q = spec.optimal_q := by
  simp [expected_update_target_eq]
  ext i
  simp
  apply Or.inr
  have := ContractingWith.fixedPoint_isFixedPt spec.contraction_of_bellman_op
  simp [Function.IsFixedPt] at this
  have := congrFun this i
  simp [optimal_q, toL2]
  simp [‚Üêthis]
  unfold ftoLinfty
  simp [toL2, toLinfty]

lemma QLearningSpec.contraction_of_expected_update_target :
  ‚àÉ Œ∑, 0 ‚â§ Œ∑ ‚àß Œ∑ < 1 ‚àß ‚àÄ q q',
    ‚Äñspec.expected_update_target q - spec.expected_update_target q'‚Äñ‚àû ‚â§
      Œ∑ * ‚Äñq - q'‚Äñ‚àû := by
  have hŒº : StochasticVec spec.MRP.Œº := by infer_instance
  let Œºmin := Finset.inf' (s := univ) (by simp) spec.MRP.Œº
  obtain ‚ü®ymin, _, _‚ü© := exists_mem_eq_inf' (s := univ) (by simp) spec.MRP.Œº
  have : 0 < Œºmin := by
    simp [Œºmin]
    intro s a
    apply pos_of_stationary spec.MRP.Œº spec.MRP.P
  have : Œºmin ‚â§ 1 := by
    simp [Œºmin]
    use ymin.1
    use ymin.2
    apply hŒº.le_one
  have := spec.hŒ≥
  refine ‚ü®?Œ∑, ?hŒ∑nonneg, ?hŒ∑lt, ?hŒ∑‚ü©
  case Œ∑ => exact 1 - Œºmin * (1 - spec.Œ≥)
  case hŒ∑nonneg =>
    simp
    apply mul_le_one‚ÇÄ
    linarith
    linarith
    linarith
  case hŒ∑lt =>
    simp
    apply @_root_.mul_pos
    linarith
    linarith
  case hŒ∑ =>
    intro q q'
    simp [expected_update_target_eq]
    conv_lhs => simp [Norm.norm]
    apply (ciSup_le_iff ?_).mpr
    intro i
    rw [add_sub_add_comm, ‚Üêmul_sub, sub_sub_sub_comm, mul_sub, sub_add,
      ‚Üêsub_one_mul, sub_eq_add_neg, ‚Üêneg_mul, neg_sub]
    grw [abs_add_le]
    simp_rw [abs_mul]
    have := PiLp.norm_apply_le (p := ‚ä§) (q - q') (i)
    simp at this
    grw [this]
    have := PiLp.norm_apply_le (p := ‚ä§)
      (spec.bellman_op q - spec.bellman_op q') (i)
    simp at this
    grw [this]
    have := spec.contraction_of_bellman_op
    have := lipschitzWith_iff_norm_sub_le.mp this.2 q q'
    unfold ftoLinfty at this
    simp [toL2, toLinfty] at this
    grw [this]
    rw [‚Üêmul_assoc, ‚Üêadd_mul]
    apply mul_le_mul_of_nonneg_right
    rw [abs_of_nonneg, abs_of_nonneg, add_sub_assoc', add_comm,
      ‚Üêadd_sub_assoc', ‚Üêmul_sub_one, ‚Üêneg_sub, mul_neg, ‚Üêsub_eq_add_neg]
    apply sub_le_sub_left
    apply mul_le_mul_of_nonneg_right
    apply inf'_le
    simp
    linarith [spec.hŒ≥.2]
    simp
    rw [‚ÜêhŒº.rowsum]
    apply single_le_sum
    intro y hy
    apply hŒº.nonneg
    simp
    apply hŒº.nonneg
    apply norm_nonneg
    apply Set.Finite.bddAbove
    apply Finite.Set.finite_range

noncomputable def QLearningSpec.pmin_aux :=
  let Œ∑ := spec.contraction_of_expected_update_target.choose
  1 / (log (1 / Œ∑) / log (Fintype.card (S √ó A)))

noncomputable def QLearningSpec.pmin : ‚Ñï := max 2 (‚åàspec.pmin_aux‚åâ‚Çä + 1)

variable {p : ‚Ñï}

instance : DecreaseAlong (half_sq_Lp (p := spec.pmin))
  (half_sq_Lp' (p := spec.pmin)) spec.expected_update_target := by
  have : 2 ‚â§ spec.pmin := by simp [QLearningSpec.pmin]
  have : Fact (1 ‚â§ (spec.pmin : ‚Ñù‚â•0‚àû)) := by apply Fact.mk (by simp; linarith)
  have : Fact (2 ‚â§ (spec.pmin : ‚Ñù‚â•0‚àû)) := by apply Fact.mk (by simp; linarith)
  set Œ∑ := spec.contraction_of_expected_update_target.choose with hŒ∑def
  obtain ‚ü®hŒ∑nonneg, hŒ∑lt, hŒ∑‚ü© :=
    spec.contraction_of_expected_update_target.choose_spec
  rw [‚ÜêhŒ∑def] at hŒ∑nonneg hŒ∑lt hŒ∑
  constructor
  refine ‚ü®?Œ∑, ?hŒ∑pos, ?hŒ∑‚ü©
  case Œ∑ =>
    exact 2 * (1 - Fintype.card (S √ó A) ^ (spec.pmin : ‚Ñù)‚Åª¬π * Œ∑)
  case hŒ∑pos =>
    by_cases hŒ∑0 : 0 = Œ∑
    simp [‚ÜêhŒ∑0]
    by_cases hsa1 : (1 : ‚Ñù) = Fintype.card (S √ó A)
    simp at hsa1 ‚ä¢
    rw [‚Üêhsa1]
    simp [hŒ∑lt]
    have hcard : 1 < Fintype.card (S √ó A) := by
      apply lt_of_le_of_ne
      apply Nat.succ_le_of_lt
      apply Fintype.card_pos_iff.mpr
      infer_instance
      exact_mod_cast hsa1
    simp at hcard
    have : spec.pmin_aux < spec.pmin := by
      simp [QLearningSpec.pmin]
      apply Or.inr
      apply (Nat.le_ceil spec.pmin_aux).trans_lt
      linarith
    have : (‚Üëspec.pmin)‚Åª¬π < (spec.pmin_aux)‚Åª¬π := by
      gcongr
      simp [QLearningSpec.pmin_aux]
      rw [‚ÜêhŒ∑def]
      apply div_pos
      apply log_pos
      exact_mod_cast hcard
      simp
      apply log_neg
      apply lt_of_le_of_ne hŒ∑nonneg hŒ∑0
      exact hŒ∑lt
    simp
    apply lt_of_lt_of_le (b := (Fintype.card (S √ó A) ^ spec.pmin_aux‚Åª¬π * Œ∑))
    simp
    gcongr
    apply Real.rpow_lt_rpow_of_exponent_lt
    exact_mod_cast hcard
    exact this
    rw [QLearningSpec.pmin_aux, ‚ÜêhŒ∑def]
    simp
    apply le_of_eq
    rw [div_eq_mul_inv, mul_comm (a := -log Œ∑), Real.rpow_mul,
      Real.rpow_inv_log]
    simp [‚ÜêReal.log_inv]
    rw [Real.exp_log, inv_mul_cancel‚ÇÄ]
    intro h; exact hŒ∑0 h.symm
    apply inv_pos_of_pos
    apply lt_of_le_of_ne hŒ∑nonneg hŒ∑0
    apply LT.lt.trans (b := 1) (by simp) (by exact_mod_cast hcard)
    apply ne_of_gt
    exact_mod_cast hcard
    apply LE.le.trans (b := 1) (by simp)
    apply le_of_lt (by exact_mod_cast hcard)
  case hŒ∑ =>
    intro y hy
    intro x
    set T := spec.expected_update_target
    have : T x - x = T x - T y + (y - x) := by
      rw [‚Üêhy]
      simp
    rw [this, inner_add_right, ‚Üêneg_sub x y, inner_neg_right]
    have := inner_gradient_half_sq_Lp_self
      (p := spec.pmin) (by linarith) (x - y)
    simp [-PiLp.inner_apply, StochasticApproximation.toL2] at this
    rw [this]
    apply LE.le.trans
    apply add_le_add
    apply le_of_abs_le
    simp
    grw [abs_sum_le_sum_abs]
    rfl
    conv_lhs =>
      congr; congr; rfl; ext i
      rw [abs_mul, mul_comm]
    grw [inner_abs_gradient_half_sq_Lp_le (p := spec.pmin) (by linarith),
      Lp_le_Linfty]
    rw [‚ÜêPi.sub_def]
    grw [hŒ∑, Linfty_le_Lp (p := spec.pmin)]
    simp [half_sq_Lp]
    ring_nf
    rfl
    linarith
    linarith

instance : LyapunovCandidate (d := d)
  (half_sq_Lp (p := spec.pmin)) (half_sq_Lp' (p := spec.pmin)) := by
  apply lyapunovCandidate_half_sq_Lp
  simp [QLearningSpec.pmin]

instance : LyapunovFunction
  (half_sq_Lp (p := spec.pmin)) (half_sq_Lp' (p := spec.pmin))
  spec.expected_update_target := by
  apply LyapunovFunction.mk

variable {q : ‚Ñï ‚Üí (‚Ñï ‚Üí (S √ó A) √ó S √ó A) ‚Üí E (Fintype.card (S √ó A))}

class QLearningIterates where
  init : ‚àÄ œâ, q 0 œâ = spec.q‚ÇÄ
  step : ‚àÄ n œâ, q (n + 1) œâ =
    q n œâ + spec.Œ± n ‚Ä¢ spec.update (q n œâ) (œâ (n + 1))

theorem ae_tendsto_of_QLearning_iid
  (hq : QLearningIterates (spec := spec) (q := q))
  (hŒ± : RobbinsMonro spec.Œ±) :
  ‚àÄ·µê œâ ‚àÇ spec.MRP.iid_samples,
    Tendsto (fun n => q n œâ) atTop (ùìù spec.optimal_q) := by
  have hq' : IteratesOfResidual q spec.q‚ÇÄ spec.Œ± spec.update_target := by
    constructor
    exact hq.init
    simp [QLearningSpec.update_target]
    exact hq.step
  let œÜ := half_sq_Lp (p := spec.pmin) (d := Fintype.card (S √ó A))
  let œÜ' := half_sq_Lp' (p := spec.pmin) (d := Fintype.card (S √ó A))
  have : LyapunovFunction œÜ œÜ' spec.expected_update_target := by infer_instance
  have : IsProbabilityMeasure spec.MRP.iid_samples := by
      apply Subtype.property
  apply ae_tendsto_of_iterates_iid_samples
    (hx := hq')
    (hFm := spec.measurable_of_udpate_target)
    (hFlip := spec.lipschitz_of_update_target)
    (hfF := spec.unfold_expected_update_target)
    (hŒ± := hŒ±)
    (œÜ := œÜ) (œÜ' := œÜ')
    (f := spec.expected_update_target)
    (hf := spec.isFixedPoint_optimal_q.symm)
  case hœÜm =>
    apply measurable_of_half_sq_Lp
    apply LE.le.trans ?_ (by apply le_max_left)
    simp
  case hgradœÜm =>
    apply measurable_of_gradient_half_sq_Lp
    apply le_max_left

theorem ae_tendsto_of_QLearning_markov
  {ŒΩ : ‚Ñù} (hŒΩ : ŒΩ ‚àà Set.Ioo (2 / 3) 1)
  (hq : QLearningIterates (spec := spec) (q := q))
  (hŒ± : spec.Œ± = fun n : ‚Ñï => inv_poly ŒΩ 2 n) :
  ‚àÄ·µê œâ ‚àÇ spec.MRP.markov_samples,
    Tendsto (fun n => q n œâ) atTop (ùìù spec.optimal_q) := by
  have hq' : IteratesOfResidual q spec.q‚ÇÄ spec.Œ± spec.update_target := by
    constructor
    exact hq.init
    simp [QLearningSpec.update_target]
    exact hq.step
  let œÜ := half_sq_Lp (p := spec.pmin) (d := Fintype.card (S √ó A))
  let œÜ' := half_sq_Lp' (p := spec.pmin) (d := Fintype.card (S √ó A))
  have : LyapunovFunction œÜ œÜ' spec.expected_update_target := by infer_instance
  have : IsProbabilityMeasure spec.MRP.iid_samples := by
      apply Subtype.property
  apply ae_tendsto_of_iterates_markov_samples_of_inv_poly
    (hŒΩ := hŒΩ)
    (hx := hq')
    (hFm := spec.measurable_of_udpate_target)
    (hFlip := spec.lipschitz_of_update_target)
    (hfF := spec.unfold_expected_update_target)
    (hŒ± := hŒ±)
    (œÜ := œÜ) (œÜ' := œÜ')
    (f := spec.expected_update_target)
    (hf := spec.isFixedPoint_optimal_q.symm)
  case hœÜm =>
    apply measurable_of_half_sq_Lp
    apply LE.le.trans ?_ (by apply le_max_left)
    simp
  case hgradœÜm =>
    apply measurable_of_gradient_half_sq_Lp
    apply le_max_left

end ReinforcementLearning.QLearning
